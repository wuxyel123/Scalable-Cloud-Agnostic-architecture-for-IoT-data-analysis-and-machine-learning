\chapter{Introduction}
\label{cap:introduction}

\section{The problem}
\label{sec:the-problem}
The rapid expansion of the Internet of Things (IoT) has transformed the way we interact with technology. IoT connects a diverse range of devices—from household appliances to industrial machinery—creating a network that continuously generates, exchanges, and analyzes vast amounts of data. This interconnected ecosystem allows for smarter, more efficient systems, automating tasks and offering insights through real-time data collection and analysis. However, while this technological advancement opens up new possibilities, it also introduces significant challenges, particularly in the management, storage, and analysis of the large volumes of data these devices produce.

This thesis addresses these challenges by developing a scalable, cloud-agnostic architecture capable of efficiently managing IoT data, facilitating analysis and machine learning applications. The problem, undertaken in collaboration with \textbf{221e}, forms the core focus of this work.

\textbf{221e} is an Italian startup, established in 2012, which specializes in leveraging advancements in IT, microelectronics, sensors, and control algorithms to develop miniaturized wireless embedded systems. 221e operates across two key areas: providing \textbf{OEM (Original Equipment Manufacturer) services} to clients seeking technological partnerships for product development and offering \textbf{finished products} in the form of multi-sensor hardware platforms to direct customers or distributors. The company primarily targets the wearable devices market and industries related to IoT, where applications are vast and continuously evolving.
Through collaboration with 221e, this thesis explores solutions to the complexities of IoT data management and analysis, developing an architecture that not only meets these demands but is also adaptable across various cloud platforms.


\section{Background}
\label{sec:background}
To understand the problem better, it is essential to define some key concepts and technologies that are relevant to the development of the proposed architecture. A brief overview of these concepts is provided below.

\subsection*{Internet of Things}
\label{sec:internet-of-things}
The Internet of Things (IoT) refers to a network of devices embedded with sensors, software, and other technologies that enable them to connect and exchange data over the internet. These devices range from everyday household items to sophisticated industrial tools, all of which collect valuable data that can be analyzed to generate insights, optimize operations, and drive innovation across various sectors, including healthcare, manufacturing, and smart cities.  In this thesis, when referring to IoT devices, we specifically mean the MuSe multi-sensor device developed by 221e\cite{site:221e}.

The MuSe device is a miniaturized multi-sensor Inertial Measurement Unit (IMU) designed to provide comprehensive data on various physical parameters. This includes measurements such as acceleration, angular velocity, and magnetic field strength. The MuSe device exemplifies a typical IoT device by being equipped with multiple sensors that continuously collect data, which can then be transmitted and analyzed for various applications.

\subsection*{Scalability}
\label{sec:scalability}
Scalability refers to a system's ability to handle an increasing workload by adding resources, either through vertical scaling (enhancing the capacity of existing machines) or horizontal scaling (adding more machines to the network). In IoT contexts, scalability is essential, as the number of connected devices and the volume of data they generate can grow exponentially. A scalable architecture ensures that the system remains efficient, responsive, and capable of handling growing demands.

\subsection*{Cloud-Agnostic}
\label{sec:cloud-agnostic}
A cloud-agnostic architecture is designed to operate seamlessly across multiple cloud service providers without requiring significant modifications. This flexibility is crucial in avoiding vendor lock-in, where a business becomes overly dependent on a single cloud provider. By enabling deployment across different platforms, a cloud-agnostic approach enhances resilience, cost optimization, and the ability to leverage the specific strengths of each cloud provider.

\subsection*{MQTT Protocol}
\label{sec:mqtt-protocol}
MQTT (Message Queuing Telemetry Transport) is a lightweight messaging protocol designed for devices with limited bandwidth, making it ideal for IoT applications. MQTT operates on a publish-subscribe model, where devices (publishers) send messages to an MQTT broker, which then forwards these messages to subscribers. 

The core concept of MQTT revolves around \textit{topics}, which act as channels or paths through which messages are transmitted. A topic is a hierarchical string that devices use to publish or subscribe to specific types of data. For example, a topic like \texttt{sensor/temperature/livingroom} could be used to send temperature readings from a sensor located in a living room. Publishers send messages to topics, and subscribers receive messages from the topics they are subscribed to, ensuring efficient data routing. Topics can be structured in multiple levels to organize data streams efficiently.

This protocol is popular in IoT because it is simple, reliable, and supports various Quality of Service (QoS) levels to ensure message delivery, even in unreliable network conditions. A more comprehensive description of MQTT can be found in \cite{site:mqtt}.


\subsection*{TLS/SSL Encryption}
\label{sec:tls-ssl-encryption}
Transport Layer Security (TLS) and its predecessor, Secure Sockets Layer (SSL), are cryptographic protocols that provide secure communication over a computer network. TLS/SSL encryption ensures that data transmitted between devices is protected from eavesdropping and tampering. In the context of IoT, securing data in transit is essential to protect sensitive information from unauthorized access.
A more comprehensive description of TLS/SSL can be found in \cite{site:tls} and \cite{site:ssl}.

\subsection*{HTTP (Hypertext Transfer Protocol)}
\label{sec:http}
HTTP is an application-layer protocol used for transmitting data over the web. It is the foundation of data communication on the internet, commonly used for exchanging hypertext documents between clients (such as browsers) and servers. HTTP operates in a request-response model, where the client sends a request, and the server returns a response. While HTTP is well-suited for many web-based services, its stateless nature, where each request is treated independently, makes it less ideal for real-time data transmission in IoT applications. Despite this, HTTP is widely used for transferring IoT data due to its simplicity and compatibility with RESTful APIs. A more comprehensive description of HTTP can be found in \cite{site:http}.

\subsection*{WebSocket}
\label{sec:websocket}
WebSocket is a communication protocol that provides full-duplex communication channels over a single, persistent connection between a client and a server. Unlike HTTP, which follows a request-response model, WebSocket allows continuous, bidirectional communication. This makes WebSocket particularly useful for applications that require real-time data exchange, such as live monitoring or control of IoT devices. Once the connection is established, the server and client can exchange data freely without the need to re-establish the connection for each transmission, making it efficient for continuous data streams. A more comprehensive description of HTTP can be found in \cite{site:websocket}.

\subsection*{Object Storage}
\label{sec:object-storage}
Object storage services offer a scalable and flexible solution for storing and managing vast amounts of unstructured data, such as files, images, videos, and any type of binary or text-based data. Unlike traditional file storage, where data is organized into a hierarchical directory structure, object storage saves data as discrete units called "objects." Each object contains not only the data itself but also metadata and a unique identifier, allowing for efficient retrieval, organization, and management.

In object storage, these objects are stored within "buckets," which serve as data containers. A bucket can hold any number of objects and is designed to scale seamlessly as data grows. This model is highly suitable for IoT environments, where devices continuously generate large quantities of diverse data types. The inclusion of metadata with each object provides context, enabling more advanced data handling and processing.

Object storage is highly durable, thanks to its use of replication across multiple physical locations or nodes, ensuring that data is protected against hardware failures. It also offers high availability and accessibility, allowing data to be retrieved from anywhere via standard protocols like HTTP. This combination of scalability, durability, and ease of access makes object storage a critical component of modern cloud-based IoT architectures, where large, diverse datasets must be stored and managed efficiently.


\subsection*{Infrastructure as a Service (IaaS)}
\label{sec:iaas}
Infrastructure as a Service (IaaS) refers to cloud services that provide virtualized computing resources over the internet. IaaS enables businesses to rent infrastructure—such as virtual machines, storage, and networking—on a pay-as-you-go basis, allowing them to scale resources according to their needs without investing in physical hardware. In the context of IoT, IaaS services provide the necessary computational power and storage to manage and process large volumes of data generated by IoT devices.

\subsection*{Platform as a Service (PaaS)}
\label{sec:paas}
Platform as a Service (PaaS) is a cloud computing model that provides developers with a comprehensive environment to build, run, and manage applications without needing to handle the complexities of the underlying infrastructure. In a PaaS environment, cloud providers deliver not just the hardware and network infrastructure but also a complete suite of development tools, runtime environments, databases, and middleware that are essential for software development.

This model allows developers to focus on writing and deploying code while the cloud provider takes care of the underlying servers, storage, networking, and security. The environment includes everything from operating systems, programming languages, frameworks, and libraries to integrated development environments (IDEs), CI/CD pipelines, and deployment tools.

PaaS is particularly beneficial for IoT applications because it simplifies the development and deployment process for complex, data-driven systems. With PaaS, developers can rapidly prototype and deploy IoT solutions, scaling them effortlessly as the number of connected devices increases. Moreover, PaaS services typically integrate with other cloud services such as databases, analytics, and machine learning, making it easier to process, store, and analyze IoT data in real-time. This model accelerates time-to-market for IoT applications by removing the need for teams to manage infrastructure and focus solely on building innovative solutions.

\subsection*{Frameworks}
\label{sec:frameworks}
A framework is a foundational structure or platform that provides predefined tools, libraries, and best practices for developing software applications. It serves as a blueprint for building applications by offering a reusable set of components, patterns, and guidelines that streamline the development process. Frameworks simplify the development of complex applications by offering built-in functionalities like database access, user authentication, and input handling, allowing developers to focus on the specific logic of their application.

\subsection*{Serverless Computing}
\label{sec:serverless}
Serverless computing is a cloud computing execution model where the cloud provider dynamically manages the infrastructure and allocates resources as needed to run applications. In this model, developers focus solely on writing code, while the cloud provider handles server provisioning, scaling, and maintenance. Serverless platforms automatically scale to meet demand and charge based only on the actual compute resources consumed, rather than a fixed amount of infrastructure.

Serverless simplifies the development of applications by removing the need to manage the underlying hardware or infrastructure, allowing developers to concentrate on their code and business logic. Popular examples of serverless services include AWS Lambda and Azure Functions which allow developers to run code in response to specific events or triggers without worrying about the underlying infrastructure.


\subsection*{Shared responsibility model}
\label{sec:shared-responsibility-model}
The shared responsibility model is a security framework that defines the responsibilities of cloud service providers and their customers in securing cloud-based applications and data. In this model, the cloud provider is responsible for securing the underlying infrastructure, such as the physical servers and network, while the customer is responsible for securing their applications, data, and access controls. By clarifying these responsibilities, the shared responsibility model helps ensure that cloud environments are adequately protected from security threats.
Each cloud provider has its own shared responsibility model, which outlines the specific security responsibilities of the provider and the customer. Understanding these models is essential for designing secure and compliant cloud architectures.

\subsection*{Apache Spark}
\label{sec:apache-spark}
Apache Spark\cite{site:spark} is an open-source, distributed computing system that provides an optimized framework for large-scale data processing. It is designed to perform tasks such as batch processing, real-time data streaming, machine learning, and graph processing efficiently across clusters of computers. Spark's in-memory computing capabilities significantly enhance performance by reducing the time taken to access data from disk, making it well-suited for processing large datasets in IoT applications. Spark integrates with a wide variety of data sources and frameworks, including Hadoop, and supports multiple programming languages such as Python, Scala, Java, and R.

\subsection*{Apache Hadoop}
\label{sec:apache-hadoop}
Apache Hadoop\cite{site:hadoop} is an open-source framework that allows for the distributed storage and processing of large datasets across clusters of computers. It uses the Hadoop Distributed File System (HDFS) for storage and MapReduce, a programming model for processing large data sets in parallel. Hadoop is designed to scale from single servers to thousands of machines, each offering local computation and storage. It is widely used for processing and analyzing big data and is highly resilient, ensuring data availability even in the event of hardware failures. Hadoop is ideal for applications requiring batch processing of massive datasets, making it suitable for IoT environments where large volumes of data are continuously generated and need to be processed efficiently.

\subsection*{Container Services}
\label{sec:container-kubernetes}
Container services provide a lightweight, portable, and consistent runtime environment for applications by packaging code and dependencies into isolated units called containers. These containers can run across different computing environments without modification. Kubernetes\cite{site:kubernetes} is an open-source platform designed to automate the deployment, scaling, and management of containerized applications. It orchestrates containers across a cluster of machines, ensuring that the right resources are allocated, workloads are distributed efficiently, and applications remain available even in the event of hardware failures.

In the context of IoT and cloud-agnostic architectures, Kubernetes ensures that services can scale horizontally to meet the growing demands of IoT data processing. By using Kubernetes, developers can deploy microservices-based applications across multiple cloud providers or on-premise infrastructure, facilitating portability and scalability. It also supports auto-scaling, fault tolerance, and continuous deployment, making it an ideal solution for managing complex and distributed IoT workloads.

\subsection*{Virtualization}
\label{sec:virtualization}
Virtualization allows for the creation of multiple virtual instances on a single physical machine, each operating as an independent computing environment. This technology is foundational to modern cloud computing, enabling efficient use of hardware resources and allowing organizations to scale their infrastructure dynamically.

Two prominent virtualization solutions are \textbf{OpenStack}\cite{site:openstack} and \textbf{VMware}\cite{site:vmware}.

\begin{itemize}
    \item \textbf{OpenStack} is an open-source cloud computing platform that controls large pools of compute, storage, and networking resources in a data center. It provides an Infrastructure as a Service (IaaS) model that supports the creation and management of virtual machines, enabling cloud providers and enterprises to build and manage private and public clouds.
    \item \textbf{VMware} is a widely used commercial solution for virtualization, offering a suite of products that provide robust virtual infrastructure management. VMware’s vSphere platform allows for the efficient deployment and management of virtual machines, supporting both on-premise and cloud environments.
\end{itemize}

Both OpenStack and VMware are crucial in cloud-agnostic architectures as they allow for the creation of virtualized environments across multiple platforms, reducing dependency on specific hardware and enabling seamless integration with container services like Kubernetes. This flexibility is essential for IoT ecosystems where workloads need to be distributed across different infrastructures while maintaining high availability and scalability.


\subsection*{ETL (Extract, Transform, Load)}
\label{sec:etl}
ETL is a process used in data integration and transformation workflows, particularly in environments where large volumes of data need to be processed and analyzed. It consists of three steps:
\begin{itemize}
    \item \textbf{Extract:} Data is collected or extracted from various sources, such as databases, IoT devices, or third-party services. This step involves connecting to data sources and gathering the relevant information needed for analysis or storage.
    \item \textbf{Transform:} The extracted data is transformed into a suitable format or structure. This may involve cleaning the data, filtering out irrelevant information, standardizing formats, aggregating values, or applying business rules to ensure consistency across different data sources.
    \item \textbf{Load:} The transformed data is loaded into a target system, such as a database or a data warehouse, where it can be stored for further analysis or machine learning processes.
\end{itemize}
ETL is commonly used in data warehousing and analytics applications, making it crucial in IoT architectures where raw data from multiple sensors needs to be cleaned and processed before being stored or analyzed. 



\subsection*{API (Application Programming Interface)}
\label{sec:api}

An Application Programming Interface (API) is a set of rules and protocols that allows different software applications to communicate with each other. It defines the methods and data formats that developers can use when interacting with a system, enabling software components to exchange information, regardless of their underlying architecture. APIs provide a standardized interface for accessing functionality and data in a controlled and structured manner.

APIs typically operate over the internet using web technologies such as HTTP and are often used to connect client applications (like web browsers or mobile apps) with backend services. APIs can be categorized into different types, such as:

\begin{itemize}
    \item \textbf{Web APIs:} These are APIs exposed over the internet via web protocols such as HTTP/HTTPS. REST (Representational State Transfer) is one of the most common architectural styles for building web APIs. REST APIs follow standard methods like GET, POST, PUT, DELETE, allowing developers to perform operations like reading, creating, updating, or deleting resources.
    
    \item \textbf{Library APIs:} These are APIs provided by libraries or frameworks, allowing developers to interact with certain functions or features within a programming language or framework. For example, an API in a data analysis library like Pandas in Python allows users to manipulate data structures easily.

    \item \textbf{Operating System APIs:} These are APIs that allow software applications to interact with the operating system, such as file management, memory allocation, or process control. Examples include POSIX APIs for Unix-like systems or WinAPI for Windows operating systems.
\end{itemize}

APIs facilitate interoperability between different systems and enable modularity by abstracting complex operations into simpler calls that are easy to integrate into other software. In cloud-based and IoT architectures, APIs are critical in ensuring that different components (such as data collection, storage, and analysis systems) can communicate seamlessly, enabling scalable and flexible solutions.

\subsection*{JSON (JavaScript Object Notation)}
\label{sec:json-format}
JSON (JavaScript Object Notation) is a lightweight data-interchange format that is easy for humans to read and write and simple for machines to parse and generate. JSON is widely used in web applications and IoT environments for data exchange because it is language-independent, meaning it can be used with any programming language.

In JSON, data is organized in key-value pairs, where keys are strings and values can be strings, numbers, arrays, or other nested JSON objects. This makes JSON ideal for transmitting structured data such as sensor readings or device states. For example, a JSON object might look like this:

\begin{verbatim}
{
    "sensor": "temperature",
    "value": 22.5,
    "unit": "Celsius",
    "timestamp": "2024-09-12T10:30:00Z"
}
\end{verbatim}

This structure makes it easy to represent complex data in a concise, readable format. In IoT applications, JSON is often used to send and receive data between devices and cloud-based platforms, enabling efficient communication. More details about JSON can be found in \cite{site:json-docs}.

\subsection*{CSV (Comma-Separated Values)}
\label{sec:csv-format}
CSV (Comma-Separated Values) is a simple file format used to store tabular data, such as spreadsheets or databases, in plain text. Each line in a CSV file corresponds to a row in a table, and the values in each row are separated by commas (or other delimiters such as tabs or semicolons). CSV is commonly used for data exchange between different applications because it is easy to generate and parse.

CSV is ideal for representing structured data, such as IoT sensor readings or logs, that need to be processed in a sequential manner. For example, a CSV file might look like this:

\begin{verbatim}
sensor,value,unit,timestamp
temperature,22.5,Celsius,2024-09-12T10:30:00Z
humidity,60,Percent,2024-09-12T10:30:00Z
\end{verbatim}

Each column in the CSV corresponds to a specific attribute, and each row represents an entry of data. CSV is particularly useful in IoT applications for batch processing and storage of large datasets. However, unlike JSON, CSV does not support complex data structures, making it less suitable for hierarchical or nested data. More details about CSV can be found in \cite{site:csv-docs}.


\section{The solution}
\label{sec:the-solution}
A systematic approach was employed to address the challenges of creating a cloud-agnostic, scalable architecture for IoT data analysis
and machine learning. The solution involved several
critical steps, each contributing to developing and validating the proposed architecture.


\subsection{Objectives and requirements}
\label{sec:objectives-and-requirements}
The primary objective of this project is to create a cloud-agnostic architecture for a network of IoT devices that can efficiently ingest, store, and analyze data from multiple sensors. The architecture must be capable of scaling both horizontally (by adding more machines) and vertically (by increasing the resources of existing machines) to accommodate the growing data demands.

\subsubsection{Cloud infrastructure}
\label{sec:cloud-infrastructure}
The architecture is designed to leverage the power of cloud services to ingest, store, and process large amounts of IoT data. The final product should be deployable on any cloud provider with minimal modification, offering customers the flexibility to choose the best provider for their needs. The cloud providers considered for this project include Aruba Cloud\cite{site:aruba-cloud}, AWS\cite{site:aws}, and Microsoft Azure\cite{site:azure}. Testing the architecture on at least two of these providers will help verify its cloud-agnostic nature.

\subsubsection{Data collection}
\label{sec:data-collection}
The system must be able to ingest data from both online devices and archive data sources. Online devices will use the MQTT protocol to send data to the cloud as soon as data is collected, where it is ingested and processed. The architecture must also support uploading files from on-premise storage, such as a Network Access Storage (NAS) or a device that collects data offline.

\subsubsection{Data processing}
\label{sec:data-processing}
The system must be capable of preprocessing data before storage, including validation, cleaning, and transformation, either in the cloud or on-premise. Additionally, the system must support post-storage processing, such as data analysis and machine learning, to extract valuable insights from the data.

\subsubsection{Security}
\label{sec:security}
Security is a critical concern for the architecture, particularly when dealing with sensitive data. The system must ensure the security of data both in transit and at rest. Data in transit must be encrypted, and the MQTT protocol should be secured using TLS/SSL encryption and certificate-based authentication. Data at rest in the cloud must also be encrypted, with secure management of encryption keys provided by the cloud service.

\subsubsection{Scalability}
The system must be able to scale horizontally by adding more instances of the same service and vertically by increasing the resources of the service. Automated scaling based on system load should be implemented to ensure the architecture can handle varying workloads efficiently. Stress tests will be conducted to verify the system's scalability under different conditions.




\subsection{Analysis of existing Solutions}
\label{sec:analysis-of-existing-solutions}
The first phase involved a comprehensive analysis of the existing technologies available for managing and processing IoT data. This included evaluating protocols for data transmission, storage solutions, and processing frameworks that could support a cloud-agnostic, scalable architecture. The focus was on identifying robust and flexible technologies capable of handling large volumes of IoT data while maintaining performance and reliability.

\subsection{Analysis of different cloud providers}
\label{sec:analysis-of-different-cloud-providers}
Given the importance of cloud-agnosticism, the next step was to analyze the capabilities of different cloud service providers, including Amazon Web Services (AWS)\cite{site:aws}, Microsoft Azure\cite{site:azure}, and Aruba Cloud\cite{site:aruba-cloud}. Each provider offers distinct features and services, and the analysis focused on understanding how these could be leveraged to build a cloud-agnostic architecture. The selection criteria not only included compatibility with IoT data handling requirements and scalability options but also took into account the expertise within the company and my familiarity with these platforms.


\subsection{Definition of a base architecture}
\label{sec:definition-of-a-base-architecture}
Based on the technology and cloud provider analyses, a base architecture was defined. This architecture was designed to be cloud-agnostic and scalable, capable of efficiently managing large volumes of IoT data. The architecture comprised components for data ingestion, storage, preprocessing, and post-processing, with an emphasis on enabling effective data analysis and machine learning operations.

\subsection{Testing on a real-world use case}
\label{sec:testing-on-a-real-world-use-case}
To validate the proposed architecture, it was tested against a real-world use case involving a network of heterogeneous IoT devices. These tests were designed to evaluate the architecture's performance, scalability, and cloud-agnostic capabilities. The results provided valuable feedback, confirming the architecture's effectiveness and informing further refinements.